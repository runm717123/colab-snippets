{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Data Loader and Preparation for USE"
      ],
      "metadata": {
        "id": "PmzczbWa4Kbr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# you can obtain the model from https://www.kaggle.com/models/google/universal-sentence-encoder/tensorFlow1/lite\n",
        "# pick the Tensorflow1 lite version mode\n",
        "\n",
        "use_model_path = '/content/drive/MyDrive/ndev-task-tracker/universal-sentence-encoder-tensorflow1-lite-v2'\n",
        "\n",
        "\n",
        "use_model = hub.load(use_model_path)\n",
        "sp = spm.SentencePieceProcessor()\n",
        "sp.load(f\"{use_model_path}/assets/universal_encoder_8k_spm.model\")"
      ],
      "metadata": {
        "id": "O5kI0kTx4J34"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocess & embedding for USE"
      ],
      "metadata": {
        "id": "gRxfG8yB3BWv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# USE Lite is designed to be smaller and mobile/web-friendly, so it does not contain its own tokenizer.\n",
        "# because the embed_fn signature of the Universal Sentence Encoder Lite model you loaded expects the input in this sparse format. If you tried to pass a dense tensor or just a list of token IDs directly, the model would likely throw an error.\n",
        "\n",
        "def to_sparse(sentences):\n",
        "    # Encode sentences to list of token ids\n",
        "    ids = [sp.encode(s) for s in sentences]\n",
        "\n",
        "    # Create values and indices for SparseTensor\n",
        "    values = [token for sent in ids for token in sent]\n",
        "    indices = [[i, j] for i, sent in enumerate(ids) for j in range(len(sent))]\n",
        "    dense_shape = [len(ids), max(len(sent) for sent in ids)]\n",
        "\n",
        "    # Convert to required tensors\n",
        "    return {\n",
        "        \"values\": tf.constant(values, dtype=tf.int64),\n",
        "        \"indices\": tf.constant(indices, dtype=tf.int64),\n",
        "        \"dense_shape\": tf.constant(dense_shape, dtype=tf.int64),\n",
        "    }\n",
        "\n",
        "\n",
        "def embed(sentences):\n",
        "  embed_fn = use_model.signatures[\"default\"]\n",
        "  sparse_input = to_sparse(sentences)\n",
        "  embeddings = embed_fn(**sparse_input)['default']\n",
        "  return embeddings.numpy()"
      ],
      "metadata": {
        "id": "eLevHMEa3A05"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7MQa5kAx24Xk"
      },
      "outputs": [],
      "source": []
    }
  ]
}